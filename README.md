# llm-rag-with-spring-ai
hi, Spring fans! In this installment I look at LLM (large language model) RAG (retrieval augmented generation) with Spring AI 


## Run in local

1. Create your own OPENAI key and add to the .zshrc or .bashrc `OPENAI_LLM_RAG_KEY`
2. Run dependencies using Docker compose `docker-compose up -d` from the service directory
3. Run the ServiceApplication from Intellij IDEA or via command line
